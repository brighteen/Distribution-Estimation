{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연구 3단계: MNIST 데이터셋 환경에서 노이즈와 GMM 복잡도 관계 분석\n",
    "\n",
    "## 연구 목표\n",
    "실제 고차원 데이터인 MNIST 데이터셋의 잠재 공간(Latent Space)에서도, '노이즈 수준'과 '최적 컴포넌트 개수'($k_{opt}$) 사이의 관계가 통제된 환경에서와 같이 동일하게 나타나는지 실증적으로 검증한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 실험 조건 설정\n",
    "모든 실험에서 동일하게 사용될 하이퍼파라미터를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험 반복 횟수 (통계적 신뢰도 확보)\n",
    "N_RUNS = 30\n",
    "\n",
    "# 테스트할 노이즈 수준 리스트 (이미지 픽셀 스케일 0-1 기준)\n",
    "NOISE_LEVELS = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "# 테스트할 GMM 컴포넌트 개수 범위\n",
    "N_COMPONENTS_RANGE = range(1, 26)\n",
    "\n",
    "# PCA로 축소할 차원 수\n",
    "N_PCA_COMPONENTS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MNIST 데이터 로딩 및 전처리\n",
    "데이터를 로드하고, PCA 모델을 미리 학습시켜 둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 모델 학습 중... (차원: 32)\n",
      "PCA 모델 학습 완료.\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_all = np.concatenate([x_train, x_test], axis=0)\n",
    "\n",
    "# 0-1 스케일로 정규화 및 1D로 펼치기\n",
    "x_all_flat = x_all.reshape(-1, 28*28) / 255.0\n",
    "\n",
    "# 차원 축소를 위한 PCA 모델 학습\n",
    "print(f\"PCA 모델 학습 중... (차원: {N_PCA_COMPONENTS})\")\n",
    "pca = PCA(n_components=N_PCA_COMPONENTS, random_state=42)\n",
    "pca.fit(x_all_flat)\n",
    "print(\"PCA 모델 학습 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 핵심 연구 로직 실행\n",
    "각 노이즈 수준에 대해 N_RUNS 만큼 실험을 반복하여, 최적의 컴포넌트 개수를 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bde94f05fd41f08006d7262b4249b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Noise Levels:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfec065bfb047a7b723ef095121ccb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs for Noise 0.0:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m N_COMPONENTS_RANGE:\n\u001b[32m     18\u001b[39m     gmm = GaussianMixture(n_components=k, random_state=\u001b[32m42\u001b[39m, reg_covar=\u001b[32m1e-6\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mgmm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_vectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     bics.append(gmm.bic(latent_vectors))\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 현재 실행(run)에서 최적의 k 찾기\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brigh\\Documents\\GitHub\\AI-Lab\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:182\u001b[39m, in \u001b[36mBaseMixture.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[32m    157\u001b[39m \n\u001b[32m    158\u001b[39m \u001b[33;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m \u001b[33;03m    The fitted mixture.\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brigh\\Documents\\GitHub\\AI-Lab\\venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brigh\\Documents\\GitHub\\AI-Lab\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:250\u001b[39m, in \u001b[36mBaseMixture.fit_predict\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.max_iter + \u001b[32m1\u001b[39m):\n\u001b[32m    248\u001b[39m     prev_lower_bound = lower_bound\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     log_prob_norm, log_resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28mself\u001b[39m._m_step(X, log_resp)\n\u001b[32m    252\u001b[39m     lower_bound = \u001b[38;5;28mself\u001b[39m._compute_lower_bound(log_resp, log_prob_norm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brigh\\Documents\\GitHub\\AI-Lab\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:312\u001b[39m, in \u001b[36mBaseMixture._e_step\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_e_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    297\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"E step.\u001b[39;00m\n\u001b[32m    298\u001b[39m \n\u001b[32m    299\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m        the point of each sample in X.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     log_prob_norm, log_resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_log_prob_resp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(log_prob_norm), log_resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brigh\\Documents\\GitHub\\AI-Lab\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:532\u001b[39m, in \u001b[36mBaseMixture._estimate_log_prob_resp\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_log_prob_resp\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    514\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[32m    515\u001b[39m \n\u001b[32m    516\u001b[39m \u001b[33;03m    Compute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    530\u001b[39m \u001b[33;03m        logarithm of the responsibilities\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     weighted_log_prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_weighted_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m     log_prob_norm = logsumexp(weighted_log_prob, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(under=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    535\u001b[39m         \u001b[38;5;66;03m# ignore underflow\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brigh\\Documents\\GitHub\\AI-Lab\\venv\\Lib\\site-packages\\sklearn\\mixture\\_base.py:485\u001b[39m, in \u001b[36mBaseMixture._estimate_weighted_log_prob\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_weighted_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    475\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001b[39;00m\n\u001b[32m    476\u001b[39m \n\u001b[32m    477\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    483\u001b[39m \u001b[33;03m    weighted_log_prob : array, shape (n_samples, n_component)\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m._estimate_log_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brigh\\Documents\\GitHub\\AI-Lab\\venv\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:839\u001b[39m, in \u001b[36mGaussianMixture._estimate_log_prob\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_log_gaussian_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmeans_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecisions_cholesky_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcovariance_type\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\brigh\\Documents\\GitHub\\AI-Lab\\venv\\Lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:487\u001b[39m, in \u001b[36m_estimate_log_gaussian_prob\u001b[39m\u001b[34m(X, means, precisions_chol, covariance_type)\u001b[39m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, (mu, prec_chol) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(means, precisions_chol)):\n\u001b[32m    486\u001b[39m         y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m         log_prob[:, k] = np.sum(np.square(y), axis=\u001b[32m1\u001b[39m)\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m covariance_type == \u001b[33m\"\u001b[39m\u001b[33mtied\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    490\u001b[39m     log_prob = np.empty((n_samples, n_components), dtype=X.dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for noise in tqdm(NOISE_LEVELS, desc=\"Noise Levels\"):\n",
    "    optimal_k_for_runs = []\n",
    "    for run in tqdm(range(N_RUNS), desc=f\"Runs for Noise {noise}\", leave=False):\n",
    "        # 1. 원본 이미지에 노이즈 주입\n",
    "        # 매 실행마다 다른 노이즈 패턴을 위해 데이터 다시 로드\n",
    "        x_all_flat_clean = x_all.reshape(-1, 28*28) / 255.0\n",
    "        noise_matrix = np.random.randn(*x_all_flat_clean.shape) * noise\n",
    "        x_all_flat_noisy = np.clip(x_all_flat_clean + noise_matrix, 0, 1)\n",
    "        \n",
    "        # 2. PCA를 이용해 차원 축소\n",
    "        latent_vectors = pca.transform(x_all_flat_noisy)\n",
    "        \n",
    "        # 3. 각 k에 대해 GMM 학습 및 BIC 계산\n",
    "        bics = []\n",
    "        for k in N_COMPONENTS_RANGE:\n",
    "            gmm = GaussianMixture(n_components=k, random_state=42, reg_covar=1e-6)\n",
    "            gmm.fit(latent_vectors)\n",
    "            bics.append(gmm.bic(latent_vectors))\n",
    "            \n",
    "        # 현재 실행(run)에서 최적의 k 찾기\n",
    "        best_k = N_COMPONENTS_RANGE[np.argmin(bics)]\n",
    "        optimal_k_for_runs.append(best_k)\n",
    "        \n",
    "    # 현재 노이즈 수준에 대한 통계치 계산\n",
    "    mean_optimal_k = np.mean(optimal_k_for_runs)\n",
    "    std_optimal_k = np.std(optimal_k_for_runs)\n",
    "    \n",
    "    results.append({\n",
    "        'noise_level': noise,\n",
    "        'mean_k_opt': mean_optimal_k,\n",
    "        'std_k_opt': std_optimal_k,\n",
    "        'all_k_opts': optimal_k_for_runs\n",
    "    })\n",
    "\n",
    "results_df_mnist = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 결과 분석 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- MNIST 실험 결과 ---\")\n",
    "print(results_df_mnist[['noise_level', 'mean_k_opt', 'std_k_opt']])\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.errorbar(\n",
    "    results_df_mnist['noise_level'], \n",
    "    results_df_mnist['mean_k_opt'], \n",
    "    yerr=results_df_mnist['std_k_opt'],\n",
    "    fmt='-D', # 마커 변경\n",
    "    capsize=5,\n",
    "    label='평균 최적 k (오차막대: 1-std)'\n",
    ")\n",
    "\n",
    "plt.title('노이즈 수준에 따른 GMM 최적 컴포넌트 개수 변화 (MNIST 잠재 공간)', fontsize=16)\n",
    "plt.xlabel('노이즈 수준 (Noise Level)', fontsize=12)\n",
    "plt.ylabel(f'최적 컴포넌트 개수 (평균, N={N_RUNS}회 실행)', fontsize=12)\n",
    "plt.xticks(NOISE_LEVELS)\n",
    "plt.grid(True, which='both', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
