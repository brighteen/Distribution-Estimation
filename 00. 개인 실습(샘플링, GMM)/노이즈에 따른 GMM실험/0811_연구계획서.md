## **연구 계획서: 데이터 노이즈가 GMM(가우시안 믹스쳐 모델)의 최적 복잡도에 미치는 영향에 대한 정량적 분석**

### 1. 연구 배경 및 목표

**배경:**
가우시안 믹스쳐 모델(GMM)은 데이터 내에 존재하는 하위 그룹들을 식별하는 강력한 비지도 학습 방법론입니다. GMM의 성능과 해석에 가장 큰 영향을 미치는 요인 중 하나는 모델의 복잡도를 결정하는 컴포넌트의 개수($k$)입니다. 예비 실험을 통해, 데이터의 노이즈 수준과 최적의 컴포넌트 개수($k$) 사이에 강한 연관성이 있음을 확인하였습니다.

**연구 목표:**
본 연구는 데이터에 포함된 **노이즈 수준(Noise Level)**과, 정보량 기준(BIC)에 의해 결정되는 **GMM의 최적 컴포넌트 개수($k_{opt}$)** 사이의 관계를 **정량적으로 규명**하는 것을 목표로 합니다. 이를 통해 통제된 환경(2D/3D 함수)에서 실제 데이터(MNIST)에 이르기까지, 이 관계의 일반화 가능성을 검증하고자 합니다.



---

### 2. 연구 질문 및 핵심 가설

**주요 연구 질문 (Research Question):**
"데이터의 노이즈 수준은 GMM의 최적 구조 복잡도에 어떤 체계적인 영향을 미치는가?"

**핵심 가설 (Hypothesis, H₁):**
"데이터에 추가되는 가우시안 노이즈의 수준과, BIC를 기준으로 측정한 GMM의 최적 컴포넌트 개수($k_{opt}$) 사이에는 **통계적으로 유의미한 음의 상관관계(negative correlation)**가 존재할 것이다."

* **귀무가설 (H₀):** 노이즈 수준은 GMM의 최적 컴포넌트 개수에 체계적인 영향을 미치지 않는다.

---

### 3. 연구 방법 및 설계

본 연구는 점진적인 복잡도 확장을 위해 두 단계로 설계됩니다.

#### **1단계: 통제된 시뮬레이션 환경 (2D & 3D 함수)**

1.  **데이터 생성:**
    * **함수:** 2차 함수($y=ax^2+bx+c$)와 3차 함수($y=ax^3+...$)를 각각 사용합니다.
    * **노이즈 변수:** `noise_levels = [0.1, 1, 5, 10, 20, 50]` 와 같이 표준편차 값의 리스트를 정의하여 노이즈 수준을 체계적으로 조절합니다.
2.  **모델링 및 평가 (통계적 신뢰도 확보):**
    * 각 `noise_level`에 대해, **총 30회**의 독립적인 실험을 반복 수행합니다.
    * 각 반복 실험 내에서, `n_components`를 1부터 25까지 변화시키며 GMM 모델을 학습하고 **BIC, AIC, Log-Likelihood**를 기록합니다.
    * 해당 실험에서 BIC 점수가 가장 낮은 최적 컴포넌트 개수($k_{opt}$)를 찾습니다.
3.  **결과 분석:**
    * 30회 반복 실험에서 얻은 $k_{opt}$ 값들의 **평균과 표준편차**를 계산합니다.
    * X축을 `noise_level`, Y축을 `평균 k_opt`로 설정하고, 표준편차를 **오차 막대(error bar)**로 표시한 2D 그래프를 작성하여 가설을 시각적으로 검증합니다.

---

#### **2단계: 실제 데이터 적용 (MNIST 데이터셋)**

1.  **전처리 및 차원 축소:**
    * 784차원의 MNIST 이미지를 GMM에 적용하기 위해 **주성분 분석(PCA)을 사용**하여 **32차원**의 잠재 공간 벡터로 일괄 변환합니다. 이는 실험의 변수를 통제하기 위함입니다.
2.  **노이즈 주입 및 모델링:**
    * 차원 축소 전의 원본 이미지에, 1단계와 동일한 `noise_levels` 리스트에 따라 가우시안 노이즈를 주입합니다.
    * 노이즈가 주입된 각 이미지 데이터셋을 PCA로 변환한 후, 1단계의 2번 과정(30회 반복 모델링 및 평가)을 동일하게 적용하여 `noise_level`에 따른 `평균 k_opt`를 도출합니다.
3.  **결과 분석:**
    * 1단계와 동일한 방식으로 X-Y 플롯 및 오차 막대를 생성하여, 통제된 환경에서 얻은 결론이 실제 데이터의 잠재 공간에서도 동일하게 나타나는지 비교 분석합니다.

---

### 4. 기대 결과 및 연구의 의의

**기대 결과:**
* 2차/3차 함수와 MNIST 데이터셋 모두에서, 노이즈 수준이 증가함에 따라 최적 컴포넌트 개수의 평균값이 감소하는 **우하향 그래프**가 도출될 것으로 기대합니다.
* 노이즈 수준이 매우 낮거나 매우 높은 극단적인 경우, $k_{opt}$ 값의 표준편차(변동성)가 중간 수준의 노이즈보다 더 작을 수 있습니다.

**연구의 의의:**
* **이론적 기여:** GMM의 복잡도와 데이터 품질 사이의 관계를 정량적으로 밝혀, 모델의 행동 원리에 대한 깊은 이론적 이해를 제공합니다.
* **실용적 기여:** 데이터의 노이즈 수준을 어림하여 GMM의 하이퍼파라미터($k$) 탐색 범위를 효율적으로 설정하는 데 실용적인 가이드라인을 제시할 수 있습니다.
* **확장성:** 본 연구의 방법론은 다른 군집화 알고리즘이나 더 복잡한 생성 모델의 특성을 분석하는 후속 연구의 기초가 될 수 있습니다.