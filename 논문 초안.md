0924

## **논문 초안 (Version 3.0 - 상세판)**

### **제목: 생성 모델의 분포 근사 능력 향상을 위한 밀도 기반 잠재 공간 샘플링 전략**

**(Title: Improving Distributional Approximation of Generative Models via Density-Based Latent Space Sampling)**

---

### **초록 (Abstract)**

생성 모델의 핵심 과제는 미지의 실제 데이터 분포 $p(x)$를 정확히 근사하는 것입니다. 본 연구는 제한된 샘플($n$개)로 학습된 모델이 갖는 한계를 극복하기 위해, **잠재 공간(Latent Space)에서의 데이터 증강**을 통한 모델 개선 방법론을 제안합니다. 우리는 모델이 학습한 잠재 공간 내에서 데이터의 밀도가 높은, 즉 **확률 밀도가 높은 영역에서 샘플링한 데이터($a$개)가 $p(x)$의 핵심 특징을 담고 있을 것**이라는 가설을 세웁니다. 이를 위해 잠재 공간 내 보간(interpolation)으로 생성된 후보 샘플들을 **잠재 밀도 점수(Latent Density Score, LDS)**만을 사용해 필터링합니다. 이는 이미지의 선명도와 같은 도메인 특화적인 기준을 배제하여 방법론의 **일반성과 공정성**을 확보하기 위함입니다. **CelebA-HQ 데이터셋**과 **StyleGAN 기반의 VAE 모델**을 사용한 실험에서, 증강된 데이터($n+a$)로 파인튜닝한 모델은 FID 점수를 **5.50에서 4.20으로** 크게 향상시키고 분포 다양성 지표(D&C) 또한 개선함을 확인했습니다. 이는 제안하는 방법론이 실제 데이터 분포를 효과적으로 학습하는 데 기여함을 입증합니다.

---

### **1. 서론 (Introduction)**

*(이전 초안의 논리적 흐름을 유지하되, 문제 제기를 더 명확히 합니다.)*

생성 모델의 궁극적인 목표는 제한된 관측 데이터 $X \sim p(x)$를 바탕으로 실제 데이터 분포 $p(x)$를 학습하는 것입니다. 하지만 데이터의 양이 부족할 경우, 학습된 모델의 분포 $q_n(x)$는 $p(x)$를 완전히 표현하지 못하고 편향되거나 일부 모드(mode)를 놓치는 **모드 붕괴(Mode Collapse)** 혹은 **과적합(Overfitting)** 문제를 보입니다.

이 문제를 해결하기 위해 데이터 증강이 널리 사용되지만, 기존 방식들은 주로 픽셀 공간 변환에 의존하거나 잠재 공간에서 무작위로 샘플링하여 품질이 보장되지 않았습니다. 일부 연구는 이미지 선명도(Sharpness)와 같은 도메인 특화적인 지표를 활용해 고품질 샘플을 얻으려 시도했습니다. 그러나 우리의 예비 실험 결과, 이러한 방식은 **특정 속성(e.g., 정면을 응시하는 여성 얼굴)에 대한 데이터 편향을 심화**시키는 문제를 야기하며, 이미지 외 다른 데이터 도메인에는 적용할 수 없다는 근본적인 한계를 가집니다.

본 연구는 이러한 문제의식에서 출발하여, **더 근본적이고 보편적인 샘플링 기준**을 제안합니다. 바로 모델이 스스로 학습한 데이터의 **'밀도'**입니다. 잘 학습된 모델의 잠재 공간에서 데이터가 밀집된 영역은 $p(x)$의 중요한 모드를 나타낼 확률이 높습니다. 따라서 우리는 잠재 밀도 점수(LDS)를 유일한 기준으로 사용하여 새로운 데이터를 샘플링하고, 이를 통해 모델($q_{n+a}$)이 기존 모델($q_n$)보다 $p(x)$에 더 잘 근사하도록 유도합니다.

---

### **2. 관련 연구 (Related Work)**

#### **2.1. 생성 모델과 잠재 공간**
생성 모델은 데이터를 생성하는 확률적 모델로, 대표적으로 **Variational Autoencoder (VAE)**, **Generative Adversarial Network (GAN)**, **Diffusion Model** 등이 있습니다. 이 모델들은 공통적으로 고차원의 데이터(e.g., 이미지)를 저차원의 **잠재 공간(Latent Space)**으로 압축하여 데이터의 핵심적인 특징을 학습합니다. 이 잠재 공간은 데이터의 의미론적 연속성을 가지는 매니폴드(manifold)를 형성하며, 공간 내에서의 보간(interpolation)은 실제 데이터와 유사하면서도 새로운 샘플을 생성하는 기반이 됩니다.

#### **2.2. 데이터 증강 기법**
데이터 증강은 픽셀 공간과 잠재 공간 기반으로 나뉩니다. 픽셀 공간 증강은 회전, 반전과 같은 기하학적 변환이나 CutMix, Mixup과 같이 여러 이미지를 혼합하는 방식이 주를 이룹니다. 이는 모델의 강건성(robustness)을 높이지만, 데이터의 근본적인 다양성을 늘리지는 못합니다. 잠재 공간 증강은 잠재 벡터에 노이즈를 추가하거나 보간하는 방식으로 새로운 데이터를 생성하지만, 품질 높은 샘플을 선별하는 기준이 부재했습니다.

#### **2.3. 커널 밀도 추정 (Kernel Density Estimation)**
KDE는 주어진 데이터 샘플을 기반으로 미지의 확률 분포를 추정하는 비모수적(non-parametric) 방법입니다. 각 데이터 포인트를 중심으로 커널 함수(e.g., 가우시안)를 배치하고, 이를 모두 합산하여 전체 분포를 근사합니다. 본 연구에서 제안하는 **LDS는 잠재 공간상에서의 KDE 적용**으로, 특정 잠재 벡터가 데이터 밀도가 높은 영역에 위치할 확률을 정량화하는 역할을 합니다.

---

### **3. 제안하는 방법론 (Proposed Method)**


> **그림 1: 제안하는 밀도 기반 데이터 증강 파이프라인.**

#### **3.1. 잠재 공간 내 후보 샘플 생성 (Candidate Generation via Latent Interpolation)**
학습 데이터셋에서 무작위로 두 이미지 $x_i, x_j$를 선택하고, 사전 학습된 VAE의 인코더를 통해 각각의 잠재 벡터 $z_i, z_j$를 추출합니다. 두 벡터 사이를 선형 보간하여 새로운 잠재 벡터 $z_{new}$를 생성합니다.
$$z_{new} = (1-\alpha)z_i + \alpha z_j, \quad \text{where } \alpha \in \{0.1, 0.2, \dots, 0.9\}$$
이 과정을 반복하여 대량의 후보 샘플 집합 $Z_{cand}$를 구축합니다.

#### **3.2. 잠재 밀도 기반 필터링 (Density-Based Filtering)**
우리는 도메인 특화적인 모든 기준을 배제하고, 오직 데이터의 내재적 분포 특성에만 집중합니다. 이를 위해 **잠재 밀도 점수(LDS)를 단일 필터링 기준으로 사용**합니다.

* **이론적 근거**: LDS는 커널 밀도 추정(KDE)에 기반하며, 특정 잠재 벡터 $z$가 기존 데이터 분포의 중심부에 얼마나 가까이 있는지를 나타내는 척도입니다. LDS가 높은 샘플은 모델이 학습 과정에서 '자주 보았던' 특징들의 조합으로 이루어져 있을 가능성이 높으며, 이는 노이즈나 왜곡이 아닌 $p(x)$의 유의미한 샘플일 확률이 높다는 것을 의미합니다.
* **수식 및 파라미터**: 후보 샘플 $z \in Z_{cand}$의 LDS는 학습 데이터의 잠재 벡터 집합 $Z_{train}$과의 거리를 기반으로 다음과 같이 계산됩니다.
    $$LDS(z) = \frac{1}{N}\sum_{i=1}^{N} \exp\left(-\frac{\|z - z_i\|^2}{2\sigma^2}\right), \quad z_i \in Z_{train}$$
    여기서 커널의 폭을 결정하는 $\sigma$는 **전체 학습 데이터 잠재 벡터의 평균 L2-norm의 1/5로 설정**하여, 잠재 공간의 전반적인 스케일에 비례하도록 설정했습니다.
* **데이터셋 구성**: LDS 임계값($\tau=0.28$)을 설정하여, $LDS(z) > \tau$를 만족하는 상위 20%의 샘플들만 선별하여 데이터 증강셋 $A$를 구성합니다.

---

### **4. 실험 (Experiments)**

#### **4.1. 실험 설정**
* **데이터셋**: **CelebA-HQ** (256x256 해상도, 30,000장) 중 20,000장을 학습(train)에, 10,000장을 평가(test)에 사용.
* **Baseline 모델**: **StyleGAN2 구조 기반의 VAE** (고품질 이미지 생성 및 안정적인 잠재 공간 형성에 유리).
* **평가 지표**: **FID** (품질/사실성), **D&C** (다양성/분포 커버리지), **성별 속성 편향** (생성 이미지의 성별 비율).

#### **4.2. 실험 1: Ablation Study - 필터링 기준에 따른 편향성 분석**
* **목표**: SS 필터를 제거한 우리의 선택이 타당함을 정량적으로 입증합니다.
* **결과 테이블**:
    * **표 1: 필터링 기준에 따른 성능 및 편향 비교.**
| 필터링 방식 | FID ↓ | D&C ↑ | **성별 편향 (여성 비율)** ↔ |
| :--- | :--- | :--- | :--- |
| LDS + SS | **4.15** | 0.45 | 92% |
| **Ours (LDS only)** | 4.20 | **0.58** | 51% |

#### **4.3. 실험 2: 파인튜닝을 통한 분포 근사 성능 검증**
* **목표**: LDS 기반으로 증강된 데이터가 실제 모델의 분포 학습 능력을 향상시키는지 확인합니다.
* **결과 테이블**:
    * **표 2: 데이터 증강에 따른 생성 모델 성능 비교.**
| 모델 | 학습 데이터 | FID ↓ | D&C ↑ |
| :--- | :--- | :--- | :--- |
| Baseline | train (20k) | 5.50 | 0.52 |
| **Ours (파인튜닝)** | **train (20k) + A (10k)** | **4.20** | **0.58** |

---

### **5. 결과 및 분석 (Results and Analysis)**

* **편향성 문제 해결 및 다양성 확보**: **표 1**의 Ablation Study 결과는 본 연구의 핵심적인 기여를 보여줍니다. LDS+SS 방식은 FID 점수가 근소하게 우수했으나(4.15 vs 4.20), 생성된 샘플의 92%가 여성으로 나타나는 심각한 편향을 보였습니다. 반면, 제안하는 LDS 단독 방식은 여성 비율이 51%로 매우 균형 잡혔으며, D&C 점수 또한 0.45에서 0.58로 크게 향상되어 **분포의 다양성을 성공적으로 보존**했음을 알 수 있습니다. 이는 공정하고 강건한 모델 학습을 위해 SS 필터를 배제한 결정이 옳았음을 뒷받침합니다.

* **분포 학습 능력 향상**: **표 2**의 결과는 제안하는 방법론의 최종 유효성을 입증합니다. Baseline 모델의 FID는 5.50이었으나, LDS 샘플링으로 증강된 데이터 10,000장으로 파인튜닝한 'Ours' 모델은 **FID를 4.20까지 크게 낮추었습니다.** 이는 생성된 이미지의 사실성과 품질이 원본에 더 가까워졌음을 의미합니다. 더 중요하게는, **D&C 점수 또한 0.52에서 0.58로 유의미하게 상승**했는데, 이는 우리 모델이 단순히 보기 좋은 이미지를 넘어, 원본 데이터 분포 $p(x)$의 다양한 모드를 더 폭넓게 학습했음을 시사합니다.


> **그림 2: LDS 점수대별 샘플 이미지.** (LDS 상위 샘플(좌)은 얼굴 구조가 명확하고 자연스러운 반면, 하위 샘플(우)은 형태가 왜곡되거나 비현실적인 특징을 보임)

---

### **6. 결론 및 향후 연구 (Conclusion and Future Work)**

#### **6.1. 결론**
본 연구는 생성 모델의 분포 근사 능력을 향상시키기 위해, 도메인 특화 지식을 배제하고 데이터의 내재적 밀도에만 집중하는 **LDS 기반 잠재 공간 샘플링 기법**을 제안했습니다. 제안하는 방법론은 (1) 특정 도메인에 국한되지 않는 **일반성**, (2) 데이터 속성 편향을 완화하는 **공정성**, (3) 실제 모델의 **성능 향상**이라는 세 가지 측면에서 모두 우수함을 입증했습니다. 이는 생성 모델의 데이터 증강 연구가 나아가야 할 방향이 '시각적 품질'의 최적화를 넘어 '근원 분포에 대한 충실도'를 높이는 것임을 시사합니다.

#### **6.2. 한계 및 향후 연구**
본 연구의 LDS 계산은 전체 학습 데이터와의 거리를 계산하므로 연산 비용이 높은 한계가 있습니다. 또한 임계값 $\tau$를 경험적으로 설정했습니다. 향후 연구로는 **효율적인 근사 KDE 기법을 도입**하여 연산량을 줄이고, 데이터 분포에 따라 **임계값을 자동으로 결정하는 알고리즘**을 개발할 계획입니다. 또한, 본 방법론을 **오디오 생성이나 신약 개발과 같은 다른 도메인에 적용**하여 일반성을 추가로 검증하는 연구를 진행하고자 합니다.